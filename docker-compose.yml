version: "3.9"

networks:
  monitor-net:
    driver: bridge
    name: monitor-net

volumes:
  pgdata:
  ollama-data:
  openwebui-data:
  zabbix-logs:

services:
  db:
    image: postgres:16-alpine
    container_name: zabbix-db
    hostname: zabbix-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: zabbix
      POSTGRES_PASSWORD: zabbix
      POSTGRES_DB: zabbix
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks: [monitor-net]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U zabbix -d zabbix"]
      interval: 30s
      timeout: 10s
      retries: 3

  zabbix-server:
    image: zabbix/zabbix-server-pgsql:ubuntu-7.4-latest
    container_name: zabbix-server
    hostname: zabbix-server
    depends_on:
      db:
        condition: service_healthy
    environment:
      DB_SERVER_HOST: zabbix-db
      POSTGRES_USER: zabbix
      POSTGRES_PASSWORD: zabbix
      POSTGRES_DB: zabbix
      ZBX_STARTPOLLERS: 10
      ZBX_DEBUGLEVEL: 3
    ports:
      - "10051:10051"
    networks: [monitor-net]
    restart: unless-stopped
    volumes:
      - zabbix-logs:/var/log/zabbix
    healthcheck:
      test: ["CMD-SHELL", "zabbix_server --test-config || exit 0"]
      interval: 60s
      timeout: 30s
      retries: 3

  zabbix-web:
    image: zabbix/zabbix-web-nginx-pgsql:ubuntu-7.4-latest
    container_name: zabbix-web
    hostname: zabbix-web
    depends_on:
      db:
        condition: service_healthy
      zabbix-server:
        condition: service_healthy
    environment:
      DB_SERVER_HOST: zabbix-db
      POSTGRES_USER: zabbix
      POSTGRES_PASSWORD: zabbix
      POSTGRES_DB: zabbix
      ZBX_SERVER_HOST: zabbix-server
      PHP_TZ: "Asia/Kolkata"
      ZBX_HISTORYSTORAGETYPES: log,text
    ports:
      - "8080:8080"
    networks: [monitor-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/api_jsonrpc.php || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  zabbix-agent2:
    image: zabbix/zabbix-agent2:ubuntu-7.4-latest
    container_name: zabbix-agent2
    hostname: zabbix-agent2
    environment:
      ZBX_HOSTNAME: docker-host
      ZBX_SERVER_HOST: zabbix-server
      ZBX_SERVER_PORT: "10051"
      ZBX_LISTENPORT: "10500"
      ZBX_ACTIVE_ALLOW: true
    ports:
      - "10500:10500"
    networks: [monitor-net]
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    hostname: ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
    networks: [monitor-net]
    restart: unless-stopped
    command: ["serve"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    
      
  # Build Zabbix MCP from local clone at ./zabbix-mcp-server
  zabbix-mcp:
    build:
      context: ./zabbix-mcp-server
      dockerfile: Dockerfile
      # Alternative options:
      # dockerfile: Dockerfile.simple  # Python 3.13 from official image
      # dockerfile: Dockerfile.stable  # (if it existed)
    image: zabbix-mcp-local:latest
    container_name: zabbix-mcp
    hostname: zabbix-mcp
    depends_on:
      zabbix-web:
        condition: service_healthy
    environment:
      ZABBIX_URL: http://zabbix-web:8080
        #ZABBIX_USER: Admin
        #ZABBIX_PASSWORD: zabbix
      ZABBIX_TOKEN: d4dbe098d5247887984de10aee996209b93c72f9ecf2801e0fe238cb0f14bdf8
      READ_ONLY: true
      DEBUG: 1
      WAIT_FOR_ZABBIX: true

    env_file:
      - ./.env           # requires ZABBIX_URL=http://zabbix-web:8080 and ZABBIX_TOKEN=...
    ports:
      - "8000:8000"
    networks: [monitor-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "/app/scripts/test_server.py"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    
  # Open WebUI (UI only; uses Ollama backend for GPU inference)
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    hostname: open-webui
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      WEBUI_AUTH: "false"
      DEFAULT_MODELS: "qwen2.5:3b-instruct"
    ports:
      - "3000:8080"
    volumes:
      - openwebui-data:/app/backend/data
    networks: [monitor-net]
    restart: unless-stopped

      # ---- Jump service (Ubuntu 22.04) ----
  jump-server:
    build:
      context: ./jump-home
      dockerfile: Dockerfile
    image: jump-server:latest
    container_name: jump-server
    hostname: jump-server
    tty: true
    stdin_open: true
    ports:
      - "8888:8888"
    networks: [monitor-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "/bin/bash", "-c", "echo 'Jump server is running'"]
      interval: 30s
      timeout: 10s
      retries: 3


  chatbot:
    build:
      context: ./chatbot
      dockerfile: Dockerfile
    image: chatbot:latest
    container_name: chatbot
    hostname: chatbot
    depends_on:
      zabbix-mcp:
        condition: service_healthy
      ollama:
        condition: service_healthy
    environment:
      MCP_URL: http://zabbix-mcp:8000/mcp
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: qwen2.5:3b-instruct
      WAIT_FOR_SERVICES: true
    ports:
      - "9000:9000"
    networks:
      - monitor-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

